{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Space Bandits Model as a Classifier\n",
    "\n",
    "RMSE validation of a contextual bandits model is covered [here](validation.ipynb).<br>\n",
    "Sometimes, we want to compare our contextual bandits model \"apples to apples\" with a binary classifier. It turns out that the sigmoid function gives us a convenient way to do just that.\n",
    "\n",
    "## Toy Data\n",
    "Using the same toy data used in the [toy problem notebook](toy_problem.ipynb), which we know  converges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>ARPU</th>\n",
       "      <th>action</th>\n",
       "      <th>reward</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23.0</td>\n",
       "      <td>87.062566</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>41.0</td>\n",
       "      <td>52.586836</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36.0</td>\n",
       "      <td>92.395865</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31.0</td>\n",
       "      <td>90.414441</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36.0</td>\n",
       "      <td>19.938699</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age       ARPU  action  reward\n",
       "0  23.0  87.062566       2       0\n",
       "1  41.0  52.586836       2       0\n",
       "2  36.0  92.395865       1       0\n",
       "3  31.0  90.414441       1       0\n",
       "4  36.0  19.938699       1       0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from random import random, randint\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "%config InlineBackend.figure_format='retina'\n",
    "##Generate Data\n",
    "\n",
    "def get_customer(ctype=None):\n",
    "    \"\"\"Customers come from two feature distributions.\n",
    "    Class 1: mean age 25, var 5 years, min age 18\n",
    "             mean ARPU 100, var 15\n",
    "    Class 2: mean age 45, var 6 years\n",
    "             mean ARPU 50, var 25\n",
    "    \"\"\"\n",
    "    if ctype is None:\n",
    "        if random() > .5: #coin toss\n",
    "            ctype = 1\n",
    "        else:\n",
    "            ctype = 2\n",
    "    age = 0\n",
    "    ft = -1\n",
    "    if ctype == 1:\n",
    "        while age < 18:\n",
    "            age = np.random.normal(25, 5)\n",
    "        while ft < 0:\n",
    "            ft = np.random.normal(100, 15)\n",
    "    if ctype == 2:\n",
    "        while age < 18:\n",
    "            age = np.random.normal(45, 6)\n",
    "        while ft < 0:\n",
    "            ft = np.random.normal(50, 25)\n",
    "    age = round(age)\n",
    "    return ctype, (age, ft)\n",
    "\n",
    "def get_rewards(customer):\n",
    "    \"\"\"\n",
    "    There are three actions:\n",
    "    promo 1: low value. 10 dollar if accept\n",
    "    promo 2: mid value. 25 dollar if accept\n",
    "    promo 3: high value. 100 dollar if accept\n",
    "    \n",
    "    Both groups are unlikely to accept promo 2.\n",
    "    Group 1 is more likely to accept promo 1.\n",
    "    Group 2 is slightly more likely to accept promo 3.\n",
    "    \n",
    "    The optimal choice for group 1 is promo 1; 90% acceptance for\n",
    "    an expected reward of 9 dollars each.\n",
    "    Group 2 accepts with 25% rate for expected 2.5 dollar reward\n",
    "    \n",
    "    The optimal choice for group 2 is promo 3; 20% acceptance for an expected\n",
    "    reward of 20 dollars each.\n",
    "    Group 1 accepts with 2% for expected reward of 2 dollars.\n",
    "    \n",
    "    The least optimal choice in all cases is promo 2; 10% acceptance rate for both groups\n",
    "    for an expected reward of 2.5 dollars.\n",
    "    \"\"\"\n",
    "    if customer[0] == 1: #group 1 customer\n",
    "        if random() > .1:\n",
    "            reward1 = 10\n",
    "        else:\n",
    "            reward1 = 0\n",
    "        if random() > .90:\n",
    "            reward2 = 25\n",
    "        else:\n",
    "            reward2 = 0\n",
    "        if random() > .98:\n",
    "            reward3 = 100\n",
    "        else:\n",
    "            reward3 = 0\n",
    "    if customer[0] == 2: #group 2 customer\n",
    "        if random() > .75:\n",
    "            reward1 = 10\n",
    "        else:\n",
    "            reward1 = 0\n",
    "        if random() > .90:\n",
    "            reward2 = 25\n",
    "        else:\n",
    "            reward2 = 0\n",
    "        if random() > .80:\n",
    "            reward3 = 100\n",
    "        else:\n",
    "            reward3 = 0\n",
    "    return np.array([reward1, reward2, reward3])\n",
    "\n",
    "def get_cust_reward():\n",
    "    \"\"\"returns a customer and reward vector\"\"\"\n",
    "    cust = get_customer()\n",
    "    reward = get_rewards(cust)\n",
    "    age = cust[1]\n",
    "    return np.array([age])/100, reward\n",
    "\n",
    "def generate_dataframe(n_rows):\n",
    "    df = pd.DataFrame()\n",
    "    ages = []\n",
    "    ARPUs = []\n",
    "    actions = []\n",
    "    rewards = []\n",
    "    for i in range(n_rows):\n",
    "        cust = get_customer()\n",
    "        reward_vec = get_rewards(cust)\n",
    "        context = np.array([cust[1]])\n",
    "        ages.append(context[0, 0])\n",
    "        ARPUs.append(context[0, 1])\n",
    "        action = np.random.randint(0,3)\n",
    "        actions.append(action)\n",
    "        reward = reward_vec[action]\n",
    "        rewards.append(reward)\n",
    "\n",
    "    df['age'] = ages\n",
    "    df['ARPU'] = ARPUs\n",
    "    df['action'] = actions\n",
    "    df['reward'] = rewards\n",
    "\n",
    "    return df\n",
    "\n",
    "df = generate_dataframe(10000)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We produce a dataset with randomly selected actions and 4000 rows.\n",
    "## Train/Validation Split\n",
    "We split the data into two equally-sized groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df.sample(frac=.5).copy()\n",
    "val = df[~df.index.isin(train.index)].copy()\n",
    "num_actions = len(train.action.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation Metric\n",
    "We'll use the ROC AUC score as a validation metric. We'll train a simple binary classifier, a logistic regression model, to \"compete\" with our bandits model. This model simply predicts convert/no convert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fts = train[['age', 'ARPU']]\n",
    "#give actions as features\n",
    "campaign_fts = pd.get_dummies(train.action)\n",
    "campaign_fts.index = train_fts.index\n",
    "X_train = pd.concat([train_fts, campaign_fts], axis=1)\n",
    "#Get labels: we are predicting conversion, so 1 if reward != 0\n",
    "train['convert'] = np.where(train.reward > 0, 1, 0)\n",
    "Y_train = train.convert\n",
    "\n",
    "#prepare X_val for later\n",
    "val_fts = val[['age', 'ARPU']]\n",
    "campaign_fts_val = pd.get_dummies(val.action)\n",
    "campaign_fts_val.index = val_fts.index\n",
    "X_val = pd.concat([val_fts, campaign_fts_val], axis=1)\n",
    "#get validation labels as well\n",
    "val['convert'] = np.where(val.reward > 0, 1, 0)\n",
    "Y_val = val.convert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression auc score:  0.782\n"
     ]
    }
   ],
   "source": [
    "classifier = LogisticRegression()\n",
    "classifier.fit(X_train, Y_train)\n",
    "pred = classifier.predict_proba(X_val)[:, 1]\n",
    "\n",
    "classifier_auc_score = roc_auc_score(Y_val, pred)\n",
    "print('Logistic regression auc score: ', round(classifier_auc_score, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bandits Model\n",
    "We fit a bandits model on the same data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing model neural_model-bnn.\n"
     ]
    }
   ],
   "source": [
    "from space_bandits import NeuralBandits\n",
    "\n",
    "model = NeuralBandits(num_actions, num_features=2, layer_sizes=[50,12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training neural_model-bnn for 100 steps...\n"
     ]
    }
   ],
   "source": [
    "model.fit(train[['age', 'ARPU']], train['action'], train['reward'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Expected Rewards\n",
    "We collect expected reward values and add them to the validation dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>ARPU</th>\n",
       "      <th>action</th>\n",
       "      <th>reward</th>\n",
       "      <th>convert</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36.0</td>\n",
       "      <td>92.395865</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.980926</td>\n",
       "      <td>1.211550</td>\n",
       "      <td>2.880790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31.0</td>\n",
       "      <td>90.414441</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.893548</td>\n",
       "      <td>0.728292</td>\n",
       "      <td>0.254755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36.0</td>\n",
       "      <td>19.938699</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.899634</td>\n",
       "      <td>4.718139</td>\n",
       "      <td>18.040534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>29.0</td>\n",
       "      <td>124.170150</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.047221</td>\n",
       "      <td>2.648925</td>\n",
       "      <td>0.541609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>39.0</td>\n",
       "      <td>38.745491</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.827022</td>\n",
       "      <td>2.408977</td>\n",
       "      <td>13.946508</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     age        ARPU  action  reward  convert          0         1          2\n",
       "2   36.0   92.395865       1       0        0   2.980926  1.211550   2.880790\n",
       "3   31.0   90.414441       1       0        0   3.893548  0.728292   0.254755\n",
       "4   36.0   19.938699       1       0        0   3.899634  4.718139  18.040534\n",
       "6   29.0  124.170150       1       0        0  10.047221  2.648925   0.541609\n",
       "10  39.0   38.745491       0       0        0   1.827022  2.408977  13.946508"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expected_values = model.expected_values(val[['age', 'ARPU']].values)\n",
    "pred = pd.DataFrame()\n",
    "for a, vals in enumerate(expected_values):\n",
    "    pred[a] = vals\n",
    "#expected reward values\n",
    "pred.index = val.index\n",
    "#add them to validation df\n",
    "val = pd.concat([val, pred], axis=1)\n",
    "val.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying the Sigmoid Function\n",
    "The bandits model treats each campaign separately, so we should apply a sigmoid function to each reward column independently. To get sensible values, mean-center and normalize each expected reward column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "val['pred'] = .5\n",
    "for a in range(num_actions):\n",
    "    #mean center and normalize expected rewards\n",
    "    val['{}_centered'.format(a)] = (val[a] - val[a].mean())/val[a].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "#Apply sigmoid to get p_pred\n",
    "for a in range(num_actions):\n",
    "    #get the rows for this action\n",
    "    slc = val[val.action==a]\n",
    "    #pass values through sigmoid\n",
    "    vals = sigmoid(slc['{}_centered'.format(a)].values)\n",
    "    #assign output to appropriate rows\n",
    "    inds = slc.index\n",
    "    val.loc[inds, 'pred'] = vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bandits auc score:  0.673\n"
     ]
    }
   ],
   "source": [
    "pred = val.pred\n",
    "\n",
    "bandits_auc_score = roc_auc_score(Y_val, pred)\n",
    "print('Bandits auc score: ', round(bandits_auc_score, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result\n",
    "We see the logistic regression model performs better by this metric. This shouldn't be a surprise! The bandits model has a much harder job! It has to perform a regression for all three campaigns - the logreg model gets all the benefits of supervision and only has a single binary output."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dev1]",
   "language": "python",
   "name": "conda-env-dev1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
