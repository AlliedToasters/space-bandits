{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Space Bandits Model as a Classifier\n",
    "\n",
    "RMSE validation of a contextual bandits model is covered [here](validation.ipynb).<br>\n",
    "Sometimes, we want to compare our contextual bandits model \"apples to apples\" with a binary classifier. It turns out that the sigmoid function gives us a convenient way to do this.\n",
    "\n",
    "## Toy Data\n",
    "Using the same toy data used in the [toy problem notebook](toy_problem.ipynb), which we know  converges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>ARPU</th>\n",
       "      <th>action</th>\n",
       "      <th>reward</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41.0</td>\n",
       "      <td>31.705625</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27.0</td>\n",
       "      <td>85.884541</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36.0</td>\n",
       "      <td>17.053245</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48.0</td>\n",
       "      <td>59.970738</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>47.0</td>\n",
       "      <td>98.454896</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age       ARPU  action  reward\n",
       "0  41.0  31.705625       0       0\n",
       "1  27.0  85.884541       0      10\n",
       "2  36.0  17.053245       1       0\n",
       "3  48.0  59.970738       1      25\n",
       "4  47.0  98.454896       2       0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from random import random, randint\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "%config InlineBackend.figure_format='retina'\n",
    "##Generate Data\n",
    "\n",
    "from space_bandits.toy_problem import generate_dataframe\n",
    "\n",
    "df = generate_dataframe(10000)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We produce a dataset with randomly selected actions and 4000 rows.\n",
    "## Train/Validation Split\n",
    "We split the data into two equally-sized groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df.sample(frac=.5).copy()\n",
    "val = df[~df.index.isin(train.index)].copy()\n",
    "num_actions = len(train.action.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation Metric\n",
    "We'll use the ROC AUC score as a validation metric. We'll train a simple binary classifier, a logistic regression model, to \"compete\" with our bandits model. This model simply predicts convert/no convert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alliedtoasters/miniconda3/envs/bandits/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fts = train[['age', 'ARPU']]\n",
    "#give actions as features\n",
    "campaign_fts = pd.get_dummies(train.action)\n",
    "campaign_fts.index = train_fts.index\n",
    "X_train = pd.concat([train_fts, campaign_fts], axis=1)\n",
    "#Get labels: we are predicting conversion, so 1 if reward != 0\n",
    "train['convert'] = np.where(train.reward > 0, 1, 0)\n",
    "Y_train = train.convert\n",
    "\n",
    "#prepare X_val for later\n",
    "val_fts = val[['age', 'ARPU']]\n",
    "campaign_fts_val = pd.get_dummies(val.action)\n",
    "campaign_fts_val.index = val_fts.index\n",
    "X_val = pd.concat([val_fts, campaign_fts_val], axis=1)\n",
    "#get validation labels as well\n",
    "val['convert'] = np.where(val.reward > 0, 1, 0)\n",
    "Y_val = val.convert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression auc score:  0.786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alliedtoasters/miniconda3/envs/bandits/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "classifier = LogisticRegression()\n",
    "classifier.fit(X_train, Y_train)\n",
    "pred = classifier.predict_proba(X_val)[:, 1]\n",
    "\n",
    "classifier_auc_score = roc_auc_score(Y_val, pred)\n",
    "print('Logistic regression auc score: ', round(classifier_auc_score, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bandits Model\n",
    "We fit a bandits model on the same data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from space_bandits import NeuralBandits\n",
    "\n",
    "model = NeuralBandits(num_actions, num_features=2, layer_sizes=[50,12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training neural_model-bnn for 100 steps...\n"
     ]
    }
   ],
   "source": [
    "model.fit(train[['age', 'ARPU']], train['action'], train['reward'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Expected Rewards\n",
    "We collect expected reward values and add them to the validation dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>ARPU</th>\n",
       "      <th>action</th>\n",
       "      <th>reward</th>\n",
       "      <th>convert</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41.0</td>\n",
       "      <td>31.705625</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>41.371531</td>\n",
       "      <td>63.260073</td>\n",
       "      <td>182.308648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27.0</td>\n",
       "      <td>85.884541</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>185.118165</td>\n",
       "      <td>115.596413</td>\n",
       "      <td>143.854397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48.0</td>\n",
       "      <td>59.970738</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>139.067486</td>\n",
       "      <td>93.874866</td>\n",
       "      <td>136.292929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>47.0</td>\n",
       "      <td>98.454896</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>227.190699</td>\n",
       "      <td>137.435247</td>\n",
       "      <td>158.761865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>51.0</td>\n",
       "      <td>85.203130</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>207.160420</td>\n",
       "      <td>123.381055</td>\n",
       "      <td>136.992186</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age       ARPU  action  reward  convert           0           1           2\n",
       "0  41.0  31.705625       0       0        0   41.371531   63.260073  182.308648\n",
       "1  27.0  85.884541       0      10        1  185.118165  115.596413  143.854397\n",
       "3  48.0  59.970738       1      25        1  139.067486   93.874866  136.292929\n",
       "4  47.0  98.454896       2       0        0  227.190699  137.435247  158.761865\n",
       "5  51.0  85.203130       1       0        0  207.160420  123.381055  136.992186"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expected_values = model.expected_values(val[['age', 'ARPU']].values)\n",
    "pred = pd.DataFrame()\n",
    "for a, vals in enumerate(expected_values):\n",
    "    pred[a] = vals\n",
    "#expected reward values\n",
    "pred.index = val.index\n",
    "#add them to validation df\n",
    "val = pd.concat([val, pred], axis=1)\n",
    "val.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying the Sigmoid Function\n",
    "The bandits model treats each campaign separately, so we should apply a sigmoid function to each reward column independently. To get sensible values, mean-center and normalize each expected reward column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "val['pred'] = .5\n",
    "for a in range(num_actions):\n",
    "    #mean center and normalize expected rewards\n",
    "    val['{}_centered'.format(a)] = (val[a] - val[a].mean())/val[a].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "#Apply sigmoid to get p_pred\n",
    "for a in range(num_actions):\n",
    "    #get the rows for this action\n",
    "    slc = val[val.action==a]\n",
    "    #pass values through sigmoid\n",
    "    vals = sigmoid(slc['{}_centered'.format(a)].values)\n",
    "    #assign output to appropriate rows\n",
    "    inds = slc.index\n",
    "    val.loc[inds, 'pred'] = vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bandits auc score:  0.625\n"
     ]
    }
   ],
   "source": [
    "pred = val.pred\n",
    "\n",
    "bandits_auc_score = roc_auc_score(Y_val, pred)\n",
    "print('Bandits auc score: ', round(bandits_auc_score, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result\n",
    "We see the logistic regression model performs better by this metric. This shouldn't be a surprise! The bandits model has a much harder job! It has to perform a regression for all three campaigns - the logreg model gets all the benefits of supervision and only has a single binary output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
